## OS

### 一、硬件结构

1、冯诺伊曼模型由运算器、控制器、存储器、输入设备、输出设备5 个部分组成

2、运算器、控制器是在中央处理器里的，存储器就我们常见的内存，输入输出设备则是计算机外接的设备，比如键盘就是输入设备，显示器就是输出设备。存储单元和输入输出设备要与中央处理器打交道的话，离不开总线。关系如下

![](https://cdn.jsdelivr.net/gh/xrj123123/Images/202409082356297.png)

3、中央处理器就是 CPU，32 位和 64 位 CPU 最主要区别在于一次能计算多少字节数据

- 32 位 CPU 一次可以计算 4 个字节； 
- 64 位 CPU 一次可以计算 8 个字节 

> 这里的 32 位和 64 位，称为 CPU 的位宽，代表的是 CPU 一次可以计算（运算）的数据量。如果是8位的cpu，那么一次只能计算1个字节，0-255范围之间的数据，无法一次完成计算1000*500，所以cpu位宽越大，能计算的数值就越大

4、寄存器用于存储计算时的数据，内存离cpu比较远，而寄存器就在cpu里，还紧挨着控制单元和逻辑运算单元，计算速度快

- 通用寄存器，用来存放需要进行运算的数据，比如需要进行加和运算的两个数据 
- 程序计数器，用来存储 CPU 要执行下一条指令「所在的内存地址」，注意不是存储了下一条要执行的指令，此时指令还在内存中，程序计数器只是存储了下一条指令「的地址」。 
- 指令寄存器，用来存放当前正在执行的指令，也就是指令本身，指令被执行完成之前，指令都存储在这里 

5、总线用于 CPU 和内存以及其他设备之间通信

- 地址总线：用于指定 CPU 将要操作的内存地址 
- 数据总线：用于读写内存的数据 
- 控制总线：用于发送和接收信号，比如中断、设备复位等信号，CPU 收到信号后自然进行响应，这时也需要控制总线 

6、cpu想要操作内存地址就需要地址总线。如果有32条地址总线，那么cpu可操作的内存大小为2^32=4G。

- 如果用 32 位 CPU 去加两个 64 位大小的数字,就需要把这 2 个 64 位的数字分成低32位和高32位。先加两个低32位数字，得到进位，然后再加两个高32位数字再加上进位，就得到结果 
- 对于64位cpu可以一次计算出两个64位数字相加的结果 
- 32位cpu的地址总线为32位，64位cpu的地址总线为48位 

7、对于存储器，速度越快，能耗越高，成本越贵，因此速度快的存储器容量都比较小

![](https://cdn.jsdelivr.net/gh/xrj123123/Images/202409082357982.png)![](https://cdn.jsdelivr.net/gh/xrj123123/Images/202409222220150.png)

8、CPU Cache

- L1缓存：每个 CPU 核心都有一块属于自己的 L1 高速缓存，指令和数据在 L1 是分开存放的，所以L1缓存通常分为数据缓存和指令缓存 
- L2缓存：L2 高速缓存每个 CPU 核心都有，但是 L2 高速缓存位置比 L1 高速缓存距离 CPU核心更远，大小比L1缓存大 
- L3缓存：L3 高速缓存通常是多个 CPU 核心共用的，位置比 L2 高速缓存距离 CPU 核心 更远，容量也更大 

![](https://cdn.jsdelivr.net/gh/xrj123123/Images/202409082358383.png)

9、CPU 并不会直接和每一种存储器设备直接打交道，而是每一种存储器设备只和它相邻的存储器设备打交道。比如，CPU Cache 的数据是从内存加载过来的,写回数据的时候也只写回到内存，CPU Cache 不会直接把数据写到磁盘，也不会从磁盘加载数据，而是先加载到内存，再从内存加载到cpu cache。

当 CPU 需要访问内存中某个数据的时候，如果寄存器有这个数据，CPU 就直接从寄存器取数据，如果寄存器没有，就去查询L1缓存，L1没有查L2，L3没有查L3，L3没有读内存

![](https://cdn.jsdelivr.net/gh/xrj123123/Images/202409082359451.png)

10、CPU Cache 是由很多个 Cache Line 组成的，Cache Line 是CPU 从内存读取数据的基本单位。CPU Cache 的数据是从内存中读取过来的，它是以一小块一小块读取数据的，这一小块数据就称为Cache Line （64字节）

> 比如，有一个 int array[100] 的数组，当载入 array[0]时，由于这个数组元素的大小在内存只占4字节，不足64字节，CPU就会顺序加载数组元素到 array[15]，意味着 array[0]~array[15] 数组元素都会被缓存在CPU Cache 中了，因此当下次访问这些数组元素时，会直接从CPU Cache 读取，而不用再从内存中读取，大大提高了 CPU 读取数据的性能。即访问数组时，顺序访问，速度比较快，因为读取第一个元素时，其他元素也会被读取到cpu cache中，这样下次就可以直接从cpu cache读取，而不需要从内存读取了

如果内存中的数据已经在 CPU Cache 中了，那CPU 访问一个内存地址的时候，会经历这4个步骤：

1. 根据内存地址中索引信息，计算在CPU Cache 中的索引，也就是找出对应的 CPU Cache Line 的地址 
2. 找到对应 CPU Cache Line 后，判断 CPU Cache Line 中的有效位，确认 CPU Cache Line 中数据是否是有效的，如果是无效的，CPU 就会直接访问内存，并重新加载数据，如果数据有效，则往下执行

3. 对比内存地址中组标记和 CPU Cache Line 中的组标记，确认 CPU Cache Line 中的数据是我们要访问的内存数据，如果不是的话，CPU 就会直接访问内存，并重新加载数据，如果是的话，则往下执行
4. 根据内存地址中偏移量信息，从CPU Cache Line 的数据块中，读取对应的字。

- 对于数据缓存，我们在遍历数据的时候，应该按照内存布局的顺序操作，这是因为 CPU Cache 是根据CPU Cache Line 批量操作数据的，所以顺序地操作连续内存数据时，性能能得到有效的提升 
- 对于指令缓存，有规律的条件分支语句能够让CPU 的分支预测器发挥作用，进一步提高执行的效率； 
- 另外，对于多核CPU 系统，线程可能在不同CPU核心来回切换，这样各个核心的缓存命中率就会受到影响，于是要想提高线程的缓存命中率，可以考虑把线程绑定 CPU 到某一个 CPU 核心。 

11、CPU在读数据时，先从CPU Cache读，读不到再去内存读。CPU如果执行写操作，写入CPU Cache后，Cache的数据就和内存数据不一致了，为了解决这个问题，有两种方案

- 写直达：CPU写入数据时，判断CPU Cache中是否存在该数据，如果存在，则将数据写入Cache，然后写入内存。否则直接将数据写入内存。但是这种方案每次都要将数据写入内存，性能不好 
- 写回：发生写操作时，新的数据仅仅被写入 Cache Block 里，只有当修改过的 Cache Block「被替换」时才需要写入内存，减少了数据写回内存的频率，提高了性能 

**具体操作**

- 如果当发生写操作时，数据已经在CPU Cache 里的话，则把数据更新到CPU Cache 里，同时标记CPU Cache 里的这个 Cache Block 为脏的，这种情况不用把数据写到内存 
- 如果当发生写操作时，数据所对应的 Cache Block 里存放的是「别的内存地址的数据」的话，就要检查这个 Cache Block 里的数据有没有被标记为脏的，如果是脏的话，我们就要把这个 Cache Block 里的数据写回到内存，然后再把当前要写入的数据，先从内存读入到 Cache Block 里，然后再把当前要写入的数据写入到 Cache Block，最后也把它标记为脏的；如果不是脏的话，把当前要写入的数据先从内存读入到 Cache Block 里，接着将数据写入到这个Cache Block 里，然后再把这个 Cache Block 标记为脏的就好了。 

12、缓存一致性问题。现在CPU都是多核的，由于L1/L2 Cache是多个核心各自独有的，此时就会出现缓存一致性问题。假设A核心和B核心同时运行两个线程，操作同一个变量i，初始值为0，此时在A和B的L1/L2 Cache中都会存在i的缓存数据，假设A中的线程执行了i++，由于写回策略，不会将数据写回内存，此时A中i的数据和B中i的数据就不一致了

为了解决这个问题，需要满足两点

- 写传播，当某个CPU核心发生写操作时，需要把该事件广播给其他核心 
- 事物的串行化：假设有多个核心对同一个数据进行修改，同步给其他核心时，要保证数据修改的顺序是一样的 写传播是通过总线嗅探实现的，当A核心修改了L1 Cache中i变量的值，通过总线将这个事件广播给其他所有的核心，每个CPU核心都会监听总线上的广播事件，并检查是否有相同数据在自己的L1 Cache中，如果存在，则进行修改

MESI协议基于总线嗅探机制实现了事物串形化。

MESI协议中有四个状态，这四个状态用来表示Cache Line的不同状态 

- Modified，已修改。脏标记，表示该Cache Block上的数据已经被更新过，但是还没写入内存 
- Exclusion，独占。数据只存储在一个CPU核心的Cache中，其他CPU核心的Cache中没有该数据，往独占的Cache中写数据，可以直接写入，不需要通知其他CPU核心 
- Shared，共享。数据在多个CPU核心的Cache中都有，更新Cache中数据时，不能直接修改，需要先向其他CPU核心广播一个请求，先把其他核心Cache中对应的Cache Line标记为无效状态，然后在更新当前Cache中的数据 
- Invalidated，已失效。表示该Cache Block里的数据已经失效，不可以读取该状态的数据 

13、CPU从内存读取数据到Cache的时候，并不是一个字节一个字节的读取，而是一块一块的读取，这一块数据被称为CPU Cache Line，Linux下是64字节，意味着L1 Cache一次载入的数据大小为64字节。

现在假设有一个双核心的CPU，这两个 CPU 核心并行运行着两个不同的线程，它们同时从内存中读取两个不同的数据，分别是类型为 long 的变量A和B，这个两个数据的地址在物理内存上是连续的，如果Cahce Line 的大小是64字节，并且变量A在Cahce Line 的开头位置，那么这两个数据是位于同一个Cache Line 中，又因为CPU Cache Line 是CPU 从内存读取数据到 Cache 的单位，所以这两个数据会被同时读入到了两个 CPU核心中各自 Cache 中。

假设A核心读取变量A，A和B属于同一个Cache Line，因此A和B都会被读取到A核心的CPU Cache上，B核心读取变量B，也会将A和B读取到B核心的CPU Cache上，由于B也读取了，因此Cache Line状态为共享。此时A核心修改变量A，将A的Cache Line变为已修改状态，将B的Cache Line变为已失效状态。然后B核心修改变量B，发现Cache Line为已失效状态，同时A核心的Cache Line为已修改状态，因此会将A的Cache Line写入内存，然后B核心重新读取数据到CPU Cache中，执行修改，然后B的Cache Line为已修改状态，A的为已失效状态。如果A和B交替执行这样的步骤，虽然操作的是不同的数据，但是Cache并没有起作用，此时就是CPU Cache伪共享问题

针对CPU缓存伪共享问题，一般通过内存填充解决，即在一个数据之后填充一段内存，使该数据单独在一个CPU Cache Line上，以空间换时间。



14、中断是系统用来响应硬件设备请求的一种机制，操作系统收到硬件的中断请求，会打断正在执行的进程，然后调用内核中的中断处理程序来响应请求。中断请求的处理程序应该要短且快，这样才能减少对正常进程运行调度地影响，而且中断处理程序可能会暂时关闭中断，这时如果中断处理程序执行时间过长，可能在还未执行完中断处理程序前，会丢失当前其他设备的中断请求。

Linux系统为了解决中断处理程序执行过长和中断丢失的问题，将中断过程分成了两个阶段，分别是「上半部和下半部分」。

- 上半部用来快速处理中断，一般会暂时关闭中断请求，主要负责处理跟硬件紧密相关或者时间敏感的事情。
- 下半部用来延迟处理上半部未完成的工作，一般以「内核线程」的方式运行。



15、计算机存储小数时，是通过**符号位+指数位+尾数**来表示的

- 符号位：表示数字是正数还是负数，为0表示正数，为1表示负数
- 指数位：指定了小数点在数据中的位置，指数可以是负数，也可以是正数，指数位的长度越长则数值的表达范围就越大
- 尾数：小数点右侧的数字，也就是小数部分，比如二进制1.0011× 2^(-2)，尾数部分就是0011，而且尾数的长度决定了这个数的精度，因此如果要表示精度更高的小数，则就要提高尾数位的长度;

> `float`：符号位1位，指数8位，尾数23位，`float`有效数字7-8位
>
> `double`：符号位1位，指数11位，尾数52位，`double`有效数字15-16位



10.625的二进制在计算机的存储方式：

- 10.625的二进制为1010.101，小数点左移三位变为1.010101，指数位为3，指数位需要+127，因此指数位为130

  > 指数可能是正数，也可能是负数，即指数是有符号的整数，而有符号整数的计算是比无符号整数麻烦的，所以为了减少不必要的麻烦，在实际存储指数的时候，需要把指数转换成无符号整数。float 的指数部分是8位，IEEE标准规定单精度浮点的指数取值范围是[-126, +127]，于是为了把指数转换成无符号整数，就要加个偏移量，比如float 的指数偏移量是127，这样指数就不会出现负数了。当我们需要计算实际的十进制数的时候，再把指数减去「偏移量」即可。

- 10.625是正数，因此符号位为0

- 尾数一共23位，因此010101后补0

  > 移动后的小数点左侧的有效位1消失了，它并没有存储到 float里。这是因为IEEE标准规定，二进制浮点数的小数点左侧只能有1位，并且还只能是1，既然这一位永远都是1，那就可以不用存起来了。于是就让23位尾数只存储小数部分，然后在计算时会自动把这个1加上，这样就可以节约1位的空间，尾数就能多存一位小数，相应的精度就更高了一点。我们在从float的二进制浮点数转换成十进制时，要考虑到这个隐含的1
  >
  > <img src="https://cdn.jsdelivr.net/gh/xrj123123/Images/202409222250925.png" style="zoom:60%;" />

![](https://cdn.jsdelivr.net/gh/xrj123123/Images/202409222243571.png)





### 二、内存管理

1、内存分段：程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。分段机制会把程序的虚拟地址分成4个段，每个段在段表中有一个项，在这一项找到段的基地址，再加上偏移量，于是就能找到物理内存中的地址

<img src="https://cdn.jsdelivr.net/gh/xrj123123/Images/202409231508396.png" style="zoom:60%;" />

分段的缺点

- 内存碎片问题

  > 1、内存占用如下图所示，此时关闭了浏览器，内存还有128+128=256M，但是两个128M内存是不连续的，无法打开200M的程序
  >
  > 2、内存分段可以做到段根据实际需求分配内存，所以有多少需求就分配多大的段，所以不会出现内部内存碎片。但是会出现外部内存碎片的问题。
  >
  > 3、解决外部内存碎片的问题可以通过**内存交换**，将音乐程序占用额256M内存写到硬盘上，然后再从硬盘读回内存，但是读回内存时，需要装载到512M内存的后边，此时就能空缺出连续的256M内存，内存交换空间就是swap分区
  >
  > <img src="https://cdn.jsdelivr.net/gh/xrj123123/Images/202409231509352.png" style="zoom:50%;" />

- 内存交换效率低

  > 如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿。



2、内存分页：分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小。这样一个连续并且尺寸固定的内存空间，我们称为页。在Linux下，每一页的大小为4KB 。当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。分页机制分配内存的最小单元是页，因此会存在内部内存碎片问题。

如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，称为**换出**。一旦需要的时候，再加载进来，称为**换入**。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，内存交换的效率就相对比较高。

<img src="https://cdn.jsdelivr.net/gh/xrj123123/Images/202409231518114.png" style="zoom:60%;" />

如果使用一级页表，需要为每个进程分配一个页表，占用内存太大。通常使用多级页表。比如在二级页表中，一级页表分为1024个页表项，每个页表项对应一个二级页表。如果某个一级页表的页表项没有被用到，就不需要创建这个页表项对应的二级页表了



3、TLB

多级页表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换就多了几道转换的工序，这显然就降低了这俩地址转换的速度，也就是带来了时间上的开销。因此设计了TLB快表，将页表和物理内存的映射关系保存在TLB中，每次查询时先查询TLB，TLB查询不到再去查页表



4、段页式管理：先将程序划分为多个有逻辑意义的段，再把每个段划分为多个页，即对分段划分出来的连续空间，划分固定大小的页



5、Linux内存分布

<img src="https://cdn.jsdelivr.net/gh/xrj123123/Images/202409231544341.png" style="zoom:80%;" />

- 32位系统的内核空间占用1G，位于最高处，剩下的 3G是用户空间;
- 64 位系统的内核空间和用户空间都是128T，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的。



6、`malloc()`分配的是虚拟内存。如果分配后的虚拟内存没有被访问的话，虚拟内存是不会映射到物理内存的，这样就不会占用物理内存了。只有在访问已分配的虚拟地址空间的时候，操作系统通过查找页表，发现虚拟内存对应的页没有在物理内存中，就会触发缺页中断，然后操作系统会建立虚拟内存和物理内存之间的映射关系。



7、虚拟内存的作用

- 虚拟内存可以使得进程对运行内存超过物理内存大小，因为程序运行符合局部性原理，CPU访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的swap 区域。
- 由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就解决了多进程之间地址冲突的问题。
- 页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。



8、主要有两类内存可以被回收，而且它们的回收方式也不同

- 文件页(File-backed Page)︰内核缓存的磁盘数据(Buffer)和内核缓存的文件数据(Cache)都叫作文件页。大部分文件页，都可以直接释放内存，以后有需要时，再从磁盘重新读取就可以了。而那些被应用程序修改过，并且暂时还没写入磁盘的数据（也就是脏页)，就得先写入磁盘，然后才能进行内存释放。所以，回收干净页的方式是直接释放内存，回收脏页的方式是先写回磁盘后再释放内存。
- 匿名页(Anonymous Page)︰这部分内存没有实际载体，不像文件缓存有硬盘文件这样一个载体，比如堆、栈数据等。这部分内存很可能还要再次被访问，所以不能直接释放内存，它们回收的方式是通过Linux的Swap机制，Swap 会把不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了。



9、4G物理内存的机器申请8G内存

- 32位操作系统：因为32位操作系统，进程最多只能申请3GB 大小的虚拟内存空间，所以进程申请8GB内存的话，在申请虚拟内存阶段就会失败(我手
- 64位操作系统：64位操作系统，进程可以使用128TB 大小的虚拟内存空间，所以进程申请8GB内存是没问题的，因为进程申请内存是申请虚拟内存，只要不读写这个虚拟内存，操作系统就不会分配物理内存。



10、swap机制：当系统的物理内存不够用的时候，就需要将物理内存中的一部分空间释放出来，以供当前运行的程序使用。那些被释放的空间可能来自一些很长时间没有什么操作的程序，这些被释放的空间会被临时保存到磁盘，等到那些程序要运行时，再从磁盘中恢复保存的数据到内存中。

另外，当内存使用存在压力的时候，会开始触发内存回收行为，会把这些不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了。这种，将内存数据换出磁盘，又从磁盘中恢复数据到内存的过程，就是Swap机制负责的。

Swap就是把一块磁盘空间或者本地文件，当成内存来使用，它包含换出和换入两个过程:

- 换出(Swap Out)，是把进程暂时不用的内存数据存储到磁盘中，并释放这些数据占用的内存
- 换入(Swap In)，是在进程再次访问这些内存的时候，把它们从磁盘读到内存中来;



11、预读失效

- Linux操作系统实现两个了LRU链表：活跃LRU链表(active_list)和非活跃LRU链表(inactive_list) 。预读的数据写入到inactive_list中，被访问的数据写入到inactive_list中
- MySQL的 Innodb存储引擎是在一个LRU链表上划分来2个区域：young区域和old 区域。



12、缓存污染

- Linux 操作系统：在内存页第二次被访问的时候，才将页从inactive list升级到active list里。
- MySQL Innodb：在内存页第二次被访问的时候，并不会马上将该页从old 区域升级到young 区域，因为还要进行停留在old区域的时间判断
  - 如果第二次的访问时间与第一次访问的时间在1秒内（默认值)，那么该页就不会被从old区域升级到young 区域
  - 如果第二次的访问时间与第一次访问的时间超过1秒，那么该页就会从old区域升级到young区域



13、页面置换算法

当CPU访问的页面不在物理内存时，便会产生一个缺页中断，请求操作系统将所缺页调入到物理内存。当出现缺页异常，需调入新页面而内存已满时，选择被置换的物理页面，也就是说选择一个物理页面换出到磁盘，然后把需要访问的页面换入到物理页。

- 最佳页面置换算法（理想情况）
- 先进先出置换算法
- 时钟页面置换算法
- 最近最久未使用的置换算法
- 最少使用置换算法



### 三、进程管理

1、进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。通常，会把交换的信息保存在进程的PCB，当要运行另外一个进程的时候，我们需要从这个进程的PCB取出上下文，然后恢复到CPU中，这使得这个进程可以继续执行



2、线程上下文切换

- 当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样
- 当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据。所以，线程的上下文切换相比进程，开销要小很多。



3、进程和线程的区别

- 进程是资源（包括内存、打开的文件等）分配的单位，线程是CPU调度的单位

- 进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈

- 线程能减少并发执行的时间和空间开销

  > 1. 线程的创建时间比进程快，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们
  > 2. 线程的终止时间比进程快，因为线程释放的资源相比进程少很多
  > 3. 同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间(虚拟内存共享)，这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的
  > 4. 由于同一进程的各线程间共享内存和文件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了



4、进程调度算法

- 先来先服务
- 短作业优先
- 高响应比优先（理想状态）
- 时间片轮转
- 优先级调度
- 多级反馈队列



5、进程间通信：每个进程的用户地址空间都是独立的，一般而言是不能互相访问的，但内核空间是每个进程都共享的，所以进程之间要通信必须通过内核。

- 匿名管道：`ps -aucf | grep mysql`，命令行里的`|`竖线就是一个管道，它的功能是将前一个命令`ps auxf `的输出，作为后一个命令 `grep mysql`的输入，可以看出管道传输数据是单向的，如果想相互通信，我们需要创建两个管道才行。同时，这种管道是没有名字，所以`|`表示的管道称为匿名管道，用完了就销毁。

  > 匿名管道的通信范围是存在父子关系的进程。因为管道没有实体，也就是没有管道文件，只能通过fork来复制父进程fd文件描述符，来达到通信的目的。在`shell`中执行`A | B`命令的时候，A和B进程都是shell创建的子进程，因此可以进行通信

- 命名管道：数据是先进先出的方式，使用前需要通过`mkfifo`命令创建，并指定管道名字。`mkfifo myPipo`，`myPipo`是管道名字

  ```sh
  $ echo "hello" > myPipo // 将数据写入管道
  						// 阻塞住了		
  ```

  往管道写入数据后，发现命令停在这了，因为管道中的数据没有被读取，只有当管道中的数据被读取后，命令才能正常退出

  ```sh
  $ cat < myPipo // 读取管道数据
  hello
  ```

  > 对于命名管道，它可以在不相关的进程间也能相互通信。因为命令管道，提前创建了一个类型为管道的设备文件，在进程里只要使用这个设备文件，就可以相互通信。不管是匿名管道还是命名管道，进程写入的数据都是缓存在内核中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循先进先出原则，不支持lseek之类的文件定位操作。

- 消息队列：消息队列是**保存在内核中的消息链表**，在发送数据时，会分成一个一个独立的数据单元，也就是消息体(数据块)，消息体是用户自定义的数据类型，消息的发送方和接收方要约定好消息体的数据类型，所以每个消息体都是固定大小的存储块，不像管道是无格式的字节流数据。如果进程从消息队列中读取了消息体，内核就会把这个消息体删除。

  消息队列生命周期随内核，如果没有释放消息队列或者没有关闭操作系统，消息队列会一直存在，而匿名管道的生命周期，是随进程的创建而建立，随进程的结束而销毁。

  > 消息队列缺点
  >
  > - 通信不及时
  > - 大小有限制
  > - 存在用户态与内核态之间数据拷贝的开销

- 共享内存：拿出一块虚拟地址空间来，映射到相同的物理内存中。这样这个进程写入的东西，另外一个进程马上就能看到了，不需要拷贝来拷贝去，大大提高了进程间通信的速度。

- 信号量：信号量其实是一个整型的计数器，主要用于实现进程间的**互斥**与**同步**。信号量表示资源的数量，控制信号量的方式有两种原子操作:

  - `Р`操作，这个操作会把信号量减去1，相减后如果信号量<0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量>=0，则表明还有资源可使用，进程可正常继续执行。
  - `V`操作，这个操作会把信号量加上1，相加后如果信号量<=0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量>0，则表明当前没有阻塞中的进程

- 信号：对于异常情况下的工作模式，需要用**信号**的方式来通知进程。

  > 信号是进程间通信机制中唯一的异步通信机制，因为可以在任何时候发送信号给某一进程，一旦有信号产生，我们就有下面这几种，用户进程对信号的处理方式。
  >
  > 1. 执行默认操作。Linux对每种信号都规定了默认操作，例如，`SIGTERM`信号，就是终止进程的意思。
  > 2. 捕捉信号。我们可以为信号定义一个信号处理函数。当信号发生时，我们就执行相应的信号处理函数。
  > 3. 忽略信号。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。有两个信号是应用进程无法捕捉和忽略的，即 `SIGILL` 和`SEGSTOP`，它们用于在任何时候中断或结束某一进程。

- socket：Socket通信不仅可以跨网络与不同主机的进程间通信，还可以在同主机上进程间通信。



6、一个进程可以创建多少个线程

- 32位系统：一个进程的虚拟内存为4G，用户空间为3G，假设创建一个线程需要10M虚拟内存，那么一共可以创建300个线程
- 64位系统：用户态的虚拟空间大到有128T，理论上不会受虚拟内存大小的限制，而会受系统的参数或性能限制。



7、线程崩溃后，会通过**信号**的方式使进程崩溃

> 1、CPU 执行正常的进程指令
>
> 2、调用kill系统调用向进程发送信号
>
> 3、进程收到操作系统发的信号，CPU暂停当前程序运行，并将控制权转交给操作系统
>
> 4、调用 kill系统调用向进程发送信号(假设为11，即`SIGSEGV`，一般非法访问内存报的都是这个错误)
>
> 5、操作系统根据情况执行相应的信号处理程序（函数)，一般执行完信号处理程序逻辑后会让进程退出。如果进程没有注册自己的信号处理函数，那么操作系统会执行默认的信号处理程序(一般最后会让进程退出)



8、线程崩溃不会导致JVM进程崩溃：JVM实现了自定义的信号处理函数，拦截了`SIGSEGC`信号，不会导致进程崩溃

> 1、发生`stackoverflow`还有空指针错误，确实都发送了`SIGSEGV`，只是虚拟机不选择退出，而是自己内部作了额外的处理，其实是恢复了线程的执行，并抛出`StackoverflowError`和`NPE`，这就是为什么JVM不会崩溃且我们能捕获这两个错误/异常的原因
>
> 2、如果针对`SIGSEGV`等信号，JVM没有做额外的处理，那么最终会走到`report_and_die`这个方法，这个方法主要做的事情是生成`hs_err_pid_xx.log crash`文件(记录了一些堆栈信息或错误)，然后退出





### 四、磁盘管理

![](https://cdn.jsdelivr.net/gh/xrj123123/Images/202409301142663.png)

磁盘中间圆的部分是磁盘的盘片，一般会有多个盘片，每个盘面都有自己的磁头。盘片中的每一层分为多个磁道，每个磁道分多个扇区，每个扇区是512字节。那么，多个具有相同编号的磁道形成一个圆柱，称之为磁盘的柱面。

磁盘调度算法的目的很简单，就是为了提高磁盘的访问性能，一般是通过优化磁盘的访问请求顺序来做到的。寻道的时间是磁盘访问最耗时的部分，如果请求顺序优化的得当，必然可以节省一些不必要的寻道时间,从而提高磁盘的访问性能。

- 先来先服务算法

- 最短寻道时间优先算法

  > 优先选择从当前磁头位置所需寻道时间最短的请求，如果序列是98，183，37，122，14，124，65，67。那么，那么根据距离磁头（53位置）最近的请求的算法，具体的请求则会是下列从左到右的顺序：65，67，37，14，98，122，124，183

- 扫描算法

  > 磁头在一个方向上移动，访问所有未完成的请求，直到磁头到达该方向上的最后的磁道，才调换方向。
  >
  > 比如磁头先响应左边的请求，直到到达最左端（0磁道）后，才开始反向移动，响应右边的请求。

- 循环扫描算法

  > 只有磁头朝某个特定方向移动时，才处理磁道访问请求，而返回时直接快速移动至最靠边缘的磁道，也就是复位磁头，这个过程是很快的，并且返回中途不处理任何请求，该算法的特点，就是磁道只响应一个方向上的请求。

- LOOK 与C-LOOK算法

  > 1、LOOK算法是针对扫描算法进行优化的。磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，反向移动的途中会响应请求。
  >
  > 2、C-LOOK算法是针对循环扫描算法进行优化的。磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，反向移动的途中不会响应请求。





### 五、网络管理

1、DMA技术

- 没有DMA时的IO过程

  > 1、CPU发出对应的指令给磁盘控制器，然后返回
  >
  > 2、磁盘控制器收到指令后，于是就开始准备数据，会把数据放入到磁盘控制器的内部缓冲区中，然后产生一个中断
  >
  > 3、CPU收到中断信号后，停下手头的工作，把磁盘控制器缓冲区中的数据读取到内核缓冲区（CPU Cache），然后再将数据从内核缓冲区拷贝到用户缓冲区，在数据传输的期间CPU是无法执行其他任务的。
  >
  > <img src="https://cdn.jsdelivr.net/gh/xrj123123/Images/202410021139622.png" style="zoom:60%;" />

- 使用DMA时的IO过程，DMA就是，在进行I/O设备和内存的数据传输的时候，数据搬运的工作全部交给DMA 控制器，而CPU不再参与任何与数据搬运相关的事情，这样CPU就可以去处理别的事务。

  > 1、用户进程调用read方法，向操作系统发出I/O请求，请求读取数据到自己的内存缓冲区中，进程进入阻塞状态
  >
  > 2、操作系统收到请求后，进一步将I/O请求发送 DMA，然后让CPU执行其他任务。DMA进一步将IO请求发送给磁盘。磁盘收到DMA的IO请求，把数据从磁盘读取到磁盘控制器的缓冲区中，当磁盘控制器的缓冲区被读满后，向DMA发起中断信号。DMA收到磁盘的信号，将磁盘控制器缓冲区中的数据拷贝到内核缓冲区中，此时不占用CPU，CPU可以执行其他任务
  >
  > 3、当DMA读取了足够多的数据，就会发送中断信号给CPU。CPU收到DMA的信号，知道数据已经准备好，于是将数据从内核拷贝到用户空间，系统调用返回
  >
  > <img src="https://cdn.jsdelivr.net/gh/xrj123123/Images/202410021142905.png" style="zoom:67%;" />



2、文件传输

- 传统文件传输通过`read`+`write`系统调用，一共发生4次上下文切换，4次数据拷贝

  > <img src="https://cdn.jsdelivr.net/gh/xrj123123/Images/202410021146782.png" style="zoom:60%;" />

- `mmap`+`write`：`mmap`系统调用函数会直接把内核缓冲区里的数据「映射」到用户空间，这样，操作系统内核与用户空间就不需要再进行任何的数据拷贝操作。此时需要4次上下文切换，3次数据拷贝

  > <img src="https://cdn.jsdelivr.net/gh/xrj123123/Images/202410021147597.png" style="zoom:60%;" />

- `sendfile`：`sendfile`可以替代`read()`和`write()`这两个系统调用，这样就可以减少一次系统调用，也就减少了2次上下文切换的开销。其次，该系统调用，可以直接把内核缓冲区里的数据拷贝到 socket缓冲区里，不再拷贝到用户态，这样就只有2次上下文切换，和3次数据拷贝

  > <img src="https://cdn.jsdelivr.net/gh/xrj123123/Images/202410021149019.png" style="zoom:60%;" />

- 零拷贝：从linux2.4开始，对于网卡支持`SG-DMA`技术的情况下，`sendfile()`系统调用可以再减少一次数据拷贝。先通过DMA将磁盘上的数据拷贝到内核缓冲区里，然后网卡的SG-DMA控制器就可以直接将内核缓存中的数据拷贝到网卡的缓冲区里，此过程不需要将数据从操作系统内核缓冲区拷贝到socket缓冲区中，这样就减少了一次数据拷贝

  > <img src="https://cdn.jsdelivr.net/gh/xrj123123/Images/202410021151087.png" style="zoom:60%;" />



3、`PageCache`：`PageCache`就是**内核缓存区**。读写磁盘相比读写内存的速度慢太多了，所以应把读写磁盘替换成读写内存。于是，通过DMA把磁盘里的数据搬运到内存里，这样就可以用读内存替换读磁盘。Mysql写日志时，就会先写到这里

> - 内存空间远比磁盘要小，内存注定只能拷贝磁盘里的一小部分数据。而程序运行的时候，具有局部性，所以刚被访问的数据在短时间内再次被访问的概率很高，于是可以用`PageCache`来缓存最近被访问的数据，当空间不足时淘汰最久未被访问的缓存。所以，读磁盘数据的时候，优先在`PageCache` 找，如果数据存在则可以直接返回，如果没有，则从磁盘中读取，然后缓存`PageCache `中。
> - 读取磁盘数据的时候，需要找到数据所在的位置，但是对于机械磁盘来说，就是通过磁头旋转到数据所在的扇区，再开始顺序读取数据，但是旋转磁头这个物理动作是非常耗时的，为了降低它的影响，`PageCache`使用了预读功能。
>   - 用户线程请求读取磁盘上文件A的offset为0-3KB范围内的数据，由于磁盘的基本读写单位为block (4KB)，于是操作系统至少会读0-4KB的内容，这恰好可以在一个page中装下。
>   - 但是操作系统出于局部性原理会选择将磁盘块offset [4KB,8KB)、[8KB,12KB)以及[12KB,16KB)都加载到内存，于是额外在内存中申请了3个page



4、大文件传输

如果你很多GB级别文件需要传输，每当用户访问这些大文件的时候，内核就会把它们载入`PageCache` 中，于是 `PageCache`空间很快被这些大文件占满。另外，由于文件太大，可能某些部分的文件数据被再次访问的概率比较低，这样就会带来2个问题

- `PageCache`由于长时间被大文件占据，其他「热点」的小文件可能就无法充分使用到 `PageCache`，于是这样磁盘读写的性能就会下降
- `PageCache `中的大文件数据，由于没有享受到缓存带来的好处，但却耗费DMA多拷贝到`PageCache`一次

所以，针对大文件的传输，不应该使用`PageCache`，也就是不应该使用零拷贝技术。大文件传输一般使用异步IO方式解决

> 1、内核向磁盘发起读请求，但是可以不等待数据就位就可以返回，于是进程此时可以处理其他任务
>
> 2、当内核将磁盘中的数据拷贝到进程缓冲区后，进程将接收到内核的通知，再去处理数据
>
> 3、传输大文件时，使用异步+直接IO，传输小文件时，使用零拷贝
>
> <img src="https://cdn.jsdelivr.net/gh/xrj123123/Images/202410021201009.png" style="zoom:60%;" />



5、边缘触发和水平触发

- 边缘触发：当被监控的Socket描述符上有可读事件发生时，服务器端只会从epoll_wait中苏醒一次，即使进程没有调用read 函数从内核读取数据，也依然只苏醒一次，因此我们程序要保证一次性将内核缓冲区的数据读取完。边缘触发一般会循环的从文件描述符中读取数据，所以会搭配非阻塞IO使用，如果使用阻塞IO，没有数据时，进程会阻塞在哪里
- 水平触发：当被监控的Socket上有可读事件发生时，服务器端不断地从epol_wait 中苏醒，直到内核缓冲区数据被read函数读完才结束，目的是告诉我们有数据需要读取



6、Reactor

- 单Reactor单线程

  > <img src="https://cdn.jsdelivr.net/gh/xrj123123/Images/202410031141739.png" style="zoom:60%;" />
  >
  > - Reactor对象的作用是监听和分发事件
  > - Acceptor对象的作用是获取连接
  > - Handler对象的作用是处理业务
  >
  > 1、Reactor对象通过select（IO多路复用接）监听事件，收到事件后通过dispatch进行分发，具体分发给Acceptor对象还是 Handler对象，还要看收到的事件类型
  >
  > 2、如果是连接建立的事件，则交由Acceptor对象进行处理，Acceptor对象会通过accept方法获取连接，并创建一个Handler对象来处理后续的响应事件
  >
  > 3、如果不是连接建立事件，则交由当前连接对应的 Handler对象来进行响应。Handler对象通过read ->业务处理-> send的流程来完成完整的业务流程。
  >
  > **缺点**
  >
  > 1、只有一个进程，无法充分利用多核CPU的性能
  >
  > 2、Handler对象在业务处理时，整个进程是无法处理其他连接的事件的，如果业务处理耗时比较长，那么就造成响应的延迟

- 单Reactor多线程

  > <img src="https://cdn.jsdelivr.net/gh/xrj123123/Images/202410031145886.png" style="zoom:70%;" />
  >
  > 1、Reactor对象通过select监听事件，收到事件后通过dispatch进行分发，具体分发给Acceptor对象还是Handler对象，还要看收到的事件类型
  >
  > 2、如果是连接建立的事件，则交由Acceptor对象进行处理，Acceptor对象会通过accept方法获取连接，并创建一个Handler对象来处理后续的响应事件
  >
  > 3、如果不是连接建立事件，则交由当前连接对应的Handler对象来进行响应
  >
  > 4、Handler对象不再负责业务处理，只负责数据的接收和发送，Handler对象通过read读取到数据后，会将数据发给子线程里的Processor对象进行业务处理
  >
  > 5、子线程里的Processor对象就进行业务处理，处理完后，将结果发给主线程中的Handler对象，接着由Handler通过send方法将响应结果发送给client

- 多Reactor多线程

  > <img src="https://cdn.jsdelivr.net/gh/xrj123123/Images/202410031155744.png" style="zoom:70%;" />
  >
  > 1、主线程中的`MainReactor`对象通过select 监控连接建立事件，收到事件后通过Acceptor对象中的accept获取连接，将新的连接分配给某个子线程
  >
  > 2、子线程中的`SubReactor`对象将`MainReactor`对象分配的连接加入select继续进行监听，并创建一个Handler 用于处理连接的响应事件。
  >
  > 3、如果有新的事件发生时，`SubReactor`对象会调用当前连接对应的 Handler对象来进行响应。Handler对象通过read ->业务处理-> send 的流程来完成完整的业务流程。
  >
  > **优点**
  >
  > 1、主线程和子线程分工明确，主线程只负责接收新连接，子线程负责完成后续的业务处理。
  >
  > 2、主线程和子线程的交互很简单，主线程只需要把新连接传给子线程，子线程无须返回数据，直接就可以在子线程将处理结果发送给客户端。



7、一致性哈希算法很好地解决了分布式系统在扩容或者缩容时，发生过多的数据迁移的问题。一致哈希算法也用了取模运算，但与哈希算法不同的是，哈希算法是对节点的数量进行取模运算，而一致哈希算法是对2^32进行取模运算，是一个固定的值。

一致哈希算法是对2^32进行取模后运算的结果值组织成一个圆环，这个圆环被称为哈希环

**—致性哈希步骤**

- 对存储节点进行哈希计算，比如根据节点的IP地址进行哈希
- 对数据进行存储或访问时，对数据进行哈希映射

映射的结果值往顺时针的方向的找到第一个节点，就是存储该数据的节点

<img src="https://cdn.jsdelivr.net/gh/xrj123123/Images/202409260013046.png" style="zoom:53%;" />

在一致哈希算法中，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响。



**优点**

1、数据均衡：在增加或删除节点时，一致性哈希算法只会影响到少量的数据迁移，保持了数据的均衡性。

2、高扩展性：当节点数发生变化时，对于已经存在的数据，只有部分数据需要重新分布，不会影响到整体的数据
结构

**缺点**

1、hash倾斜：在节点数较少的情况下，由于哈希空间是有限的，节点的分布可能不够均匀，导致数据倾斜。

2、节点的频繁变更：如果频繁添加或删除节点，可能导致大量的数据迁移，造成系统压力。



**虚拟节点**

为了解决一致性哈希算法不能够均匀的分布节点的问题，就需要引入虚拟节点，对一个真实节点做多个副本。不再将真实节点映射到哈希环上，而是将虚拟节点映射到哈希环上，并将虚拟节点映射到实际节点，所以这里有「两层」映射关系。

引入虚拟节点后，可以会提高节点的均衡度，还会提高系统的稳定性。所以，带虚拟节点的一致性哈希方法不仅适合硬件配置不同的节点的场景，而且适合节点规模会发生变化的场景。





### 六、文件

1、Linux文件系统会为每个文件分配两个数据结构：索引节点(index node)和目录项(directory entry)，它们主要用来记录文件的元信息和目录层次结构

- 索引节点`inode`，用来记录文件的元信息，比如`inode`编号、文件大小、访问权限、创建时间、修改时间、数据在磁盘的位置等等。索引节点是文件的唯一标识，它们之间一一对应，也同样都会被存储在硬盘中，所以索引节点同样占用磁盘空间。
- 目录项`dentry`，用来记录文件的名字、索引节点指针以及与其他目录项的层级关联关系。多个目录项关联起来，就会形成目录结构，但它与索引节点不同的是，目录项是由内核维护的一个数据结构，不存放于磁盘，而是缓存在内存。



2、磁盘读写的最小单位是扇区，扇区的大小只有`512B` 大小。文件系统把多个扇区组成了一个逻辑块，每次读写的最小单位就是逻辑块（数据块)，Linux中的逻辑块大小为`4KB`，也就是一次性读写8个扇区，这将大大提高了磁盘的读写的效率。

> <img src="https://cdn.jsdelivr.net/gh/xrj123123/Images/202410042000899.png" style="zoom:50%;" />



3、文件存储

- 连续空间存放

  > 文件存放在磁盘连续的物理空间中。这种模式下，文件的数据都是紧密相连，读写效率很高，因为一次磁盘寻道就可以读出整个文件。文件头里需要指定起始块的位置和长度，有了这两个信息就可以很好的表示文件存放方式是一块连续的磁盘空间。
  >
  > 但是有磁盘空间碎片和文件长度不易扩展的问题
  >
  > <img src="https://cdn.jsdelivr.net/gh/xrj123123/Images/202410042002220.png" style="zoom:50%;" />

- 非连续空间存放

  - 链表方式

    - 隐式链表

      > 文件头要包含第一块和最后一块的位置，并且每个数据块里面留出一个指针空间，用来存放下一个数据块的位置，这样一个数据块连着一个数据块，从链头开始就可以顺着指针找到所有的数据块，所以存放的方式可以是不连续的。
      >
      > 只能顺序访问且指针消耗空间
      >
      > <img src="https://cdn.jsdelivr.net/gh/xrj123123/Images/202410042004138.png" style="zoom:67%;" />

    - 显式链表

      > 把用于链接文件各数据块的指针，显式地存放在内存的一张链接表中，该表在整个磁盘仅设置一张，每个表项中存放链接指针，指向下一个数据块号。
      >
      > 文件A：4、7、2、10、12
      >
      > 文件B：6、3、11、14
      >
      > <img src="https://cdn.jsdelivr.net/gh/xrj123123/Images/202410042007420.png" style="zoom:50%;" />

  - 索引方式

    > 为每个文件创建一个索引数据块，里面存放的是指向文件数据块的指针列表
    >
    > <img src="https://cdn.jsdelivr.net/gh/xrj123123/Images/202410042011529.png" style="zoom:67%;" />



4、空闲空间管理

- 空闲表法

  > 为所有空闲空间建立一张表，表内容包括空闲区的第一个块号和该空闲区的块个数，这个方式是连续分配的。
  >
  > <img src="https://cdn.jsdelivr.net/gh/xrj123123/Images/202410042013014.png" style="zoom:67%;" />

- 空闲链表法

  > 每一个空闲块里有一个指针指向下一个空闲块，这样也能很方便的找到空闲块并管理起来。
  >
  > <img src="https://cdn.jsdelivr.net/gh/xrj123123/Images/202410042014066.png" style="zoom:50%;" />

- 位图法

  > 利用二进制的一位来表示磁盘中一个盘块的使用情况，磁盘上所有的盘块都有一个二进制位与之对应。当值为0时，表示对应的盘块空闲，值为1时，表示对应的盘块已分配。
  >
  > ```
  > 1111110011111110001110110111111100111 ...
  > ```



5、硬链接：硬链接是多个目录项中的索引节点指向一个文件，也就是指向同一个`inode`，但是 `inode`是不可能跨越文件系统的，每个文件系统都有各自的`inode`数据结构和列表，**所以硬链接是不可用于跨文件系统的**。由于多个目录项都是指向一个`inode`，那么只有删除文件的所有硬链接以及源文件时，系统才会彻底删除该文件。

<img src="https://cdn.jsdelivr.net/gh/xrj123123/Images/202410042017069.png" style="zoom:67%;" />



6、软链接：软链接相当于重新创建一个文件，这个文件有独立的`inode`，但是这个文件的内容是另外一个文件的路径，所以访问软链接的时候，实际上相当于访问到了另外一个文件，所以软链接是可以跨文件系统的，甚至目标文件被删除了，链接文件还是在的，只不过指向的文件找不到了而已。

<img src="https://cdn.jsdelivr.net/gh/xrj123123/Images/202410042018554.png" style="zoom:67%;" />



7、进程在执行write (使用缓冲IO）系统调用的时候，实际上是将文件数据写到了内核的`pageCache`，它是文件系统中用于缓存文件数据的缓冲，所以即使进程崩溃了，文件数据还是保留在内核的`pageCache`，读数据的时候，也是从内核的`pageCache`读取，因此还是依然读的进程崩溃前写入的数据。

内核会找个合适的时机，将`pageCache`中的数据持久化到磁盘。但是如果`pagCache`里的文件数据，在持久化到磁盘化到磁盘之前，系统发生了崩溃，那这部分数据就会丢失了。

我们也可以在程序里调用`fsync `函数，在写文件的时候，立刻将文件数据持久化到磁盘，这样就可以解决系统崩溃导致的文件数据丢失的问题。





### 七、设备管理

我们的电脑设备可以接非常多的输入输出设备，比如键盘、鼠标、显示器、网卡、硬盘、打印机、音响等等，每个设备的用法和功能都不同， 为了屏蔽设备之间的差异，每个设备都有一个设备控制器(Device Control)，比如硬盘有硬盘控制器、显示器有视频控制器等。

虽然设备控制器屏蔽了设备的众多细节，但每种设备控制器的寄存器、缓冲区等使用模式都是不同的，所以为了屏蔽设备控制器的差异，引入了设备驱动程序。

设备控制器属于硬件，设备驱动程序属于操作系统的一部分，操作系统的内核代码可以像本地调用代码一样使用设备驱动程序的接口，而设备驱动程序是面向设备控制器的代码，它发出操控设备控制器的指令后，才可以操作设备控制器。不同的设备控制器虽然功能不同，但是设备驱动程序会提供统一的接口给操作系统，这样不同的设备驱动

<img src="https://cdn.jsdelivr.net/gh/xrj123123/Images/202410051209390.png" style="zoom:67%;" />
