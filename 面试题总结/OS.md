## OS

1、冯诺伊曼模型由运算器、控制器、存储器、输入设备、输出设备5 个部分组成

2、运算器、控制器是在中央处理器里的，存储器就我们常见的内存，输入输出设备则是计算机外接的设备，比如键盘就是输入设备，显示器就是输出设备。存储单元和输入输出设备要与中央处理器打交道的话，离不开总线。关系如下

![](https://cdn.jsdelivr.net/gh/xrj123123/Images/202409082356297.png)

3、中央处理器就是 CPU，32 位和 64 位 CPU 最主要区别在于一次能计算多少字节数据

- 32 位 CPU 一次可以计算 4 个字节； 
- 64 位 CPU 一次可以计算 8 个字节 

> 这里的 32 位和 64 位，称为 CPU 的位宽，代表的是 CPU 一次可以计算（运算）的数据量。如果是8位的cpu，那么一次只能计算1个字节，0-255范围之间的数据，无法一次完成计算1000*500，所以cpu位宽越大，能计算的数值就越大

4、寄存器用于存储计算时的数据，内存离cpu比较远，而寄存器就在cpu里，还紧挨着控制单元和逻辑运算单元，计算速度快

- 通用寄存器，用来存放需要进行运算的数据，比如需要进行加和运算的两个数据 
- 程序计数器，用来存储 CPU 要执行下一条指令「所在的内存地址」，注意不是存储了下一条要执行的指令，此时指令还在内存中，程序计数器只是存储了下一条指令「的地址」。 
- 指令寄存器，用来存放当前正在执行的指令，也就是指令本身，指令被执行完成之前，指令都存储在这里 

5、总线用于 CPU 和内存以及其他设备之间通信

- 地址总线：用于指定 CPU 将要操作的内存地址 
- 数据总线：用于读写内存的数据 
- 控制总线：用于发送和接收信号，比如中断、设备复位等信号，CPU 收到信号后自然进行响应，这时也需要控制总线 

6、cpu想要操作内存地址就需要地址总线。如果有32条地址总线，那么cpu可操作的内存大小为2^32=4G。

- 如果用 32 位 CPU 去加两个 64 位大小的数字,就需要把这 2 个 64 位的数字分成低32位和高32位。先加两个低32位数字，得到进位，然后再加两个高32位数字再加上进位，就得到结果 
- 对于64位cpu可以一次计算出两个64位数字相加的结果 
- 32位cpu的地址总线为32位，64位cpu的地址总线为48位 

7、对于存储器，速度越快，能耗越高，成本越贵，因此速度快的存储器容量都比较小

![](https://cdn.jsdelivr.net/gh/xrj123123/Images/202409082357982.png)![image-20240908235804121](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240908235804121.png)

8、CPU Cache

- L1缓存：每个 CPU 核心都有一块属于自己的 L1 高速缓存，指令和数据在 L1 是分开存放的，所以L1缓存通常分为数据缓存和指令缓存 
- L2缓存：L2 高速缓存每个 CPU 核心都有，但是 L2 高速缓存位置比 L1 高速缓存距离 CPU核心更远，大小比L1缓存大 
- L3缓存：L3 高速缓存通常是多个 CPU 核心共用的，位置比 L2 高速缓存距离 CPU 核心 更远，容量也更大 

![](https://cdn.jsdelivr.net/gh/xrj123123/Images/202409082358383.png)

9、CPU 并不会直接和每一种存储器设备直接打交道，而是每一种存储器设备只和它相邻的存储器设备打交道。比如，CPU Cache 的数据是从内存加载过来的,写回数据的时候也只写回到内存，CPU Cache 不会直接把数据写到磁盘，也不会从磁盘加载数据，而是先加载到内存，再从内存加载到cpu cache。

当 CPU 需要访问内存中某个数据的时候，如果寄存器有这个数据，CPU 就直接从寄存器取数据，如果寄存器没有，就去查询L1缓存，L1没有查L2，L3没有查L3，L3没有读内存

![](https://cdn.jsdelivr.net/gh/xrj123123/Images/202409082359451.png)

10、CPU Cache 是由很多个 Cache Line 组成的，Cache Line 是CPU 从内存读取数据的基本单位。CPU Cache 的数据是从内存中读取过来的，它是以一小块一小块读取数据的，这一小块数据就称为Cache Line （64字节）

> 比如，有一个 int array[100] 的数组，当载入 array[0]时，由于这个数组元素的大小在内存只占4字节，不足64字节，CPU就会顺序加载数组元素到 array[15]，意味着 array[0]~array[15] 数组元素都会被缓存在CPU Cache 中了，因此当下次访问这些数组元素时，会直接从CPU Cache 读取，而不用再从内存中读取，大大提高了 CPU 读取数据的性能。即访问数组时，顺序访问，速度比较快，因为读取第一个元素时，其他元素也会被读取到cpu cache中，这样下次就可以直接从cpu cache读取，而不需要从内存读取了

如果内存中的数据已经在 CPU Cache 中了，那CPU 访问一个内存地址的时候，会经历这4个步骤：

1. 根据内存地址中索引信息，计算在CPU Cache 中的索引，也就是找出对应的 CPU Cache Line 的地址 
2. 找到对应 CPU Cache Line 后，判断 CPU Cache Line 中的有效位，确认 CPU Cache Line 中数据是否是有效的，如果是无效的，CPU 就会直接访问内存，并重新加载数据，如果数据有效，则往下执行

3. 对比内存地址中组标记和 CPU Cache Line 中的组标记，确认 CPU Cache Line 中的数据是我们要访问的内存数据，如果不是的话，CPU 就会直接访问内存，并重新加载数据，如果是的话，则往下执行
4. 根据内存地址中偏移量信息，从CPU Cache Line 的数据块中，读取对应的字。

- 对于数据缓存，我们在遍历数据的时候，应该按照内存布局的顺序操作，这是因为 CPU Cache 是根据CPU Cache Line 批量操作数据的，所以顺序地操作连续内存数据时，性能能得到有效的提升 
- 对于指令缓存，有规律的条件分支语句能够让CPU 的分支预测器发挥作用，进一步提高执行的效率； •另外，对于多核CPU 系统，线程可能在不同CPU核心来回切换，这样各个核心的缓存命中率就会受到影响，于是要想提高线程的缓存命中率，可以考虑把线程绑定 CPU 到某一个 CPU 核心。 

11、CPU在读数据时，先从CPU Cache读，读不到再去内存读。CPU如果执行写操作，写入CPU Cache后，Cache的数据就和内存数据不一致了，为了解决这个问题，有两种方案

- 写直达：CPU写入数据时，判断CPU Cache中是否存在该数据，如果存在，则将数据写入Cache，然后写入内存。否则直接将数据写入内存。但是这种方案每次都要将数据写入内存，性能不好 •写回：发生写操作时，新的数据仅仅被写入 Cache Block 里，只有当修改过的 Cache Block「被替换」时才需要写入内存，减少了数据写回内存的频率，提高了性能 

**具体操作**

- 如果当发生写操作时，数据已经在CPU Cache 里的话，则把数据更新到CPU Cache 里，同时标记CPU Cache 里的这个 Cache Block 为脏的，这种情况不用把数据写到内存 
- 如果当发生写操作时，数据所对应的 Cache Block 里存放的是「别的内存地址的数据」的话，就要检查这个 Cache Block 里的数据有没有被标记为脏的，如果是脏的话，我们就要把这个 Cache Block 里的数据写回到内存，然后再把当前要写入的数据，先从内存读入到 Cache Block 里，然后再把当前要写入的数据写入到 Cache Block，最后也把它标记为脏的；如果不是脏的话，把当前要写入的数据先从内存读入到 Cache Block 里，接着将数据写入到这个Cache Block 里，然后再把这个 Cache Block 标记为脏的就好了。 

12、缓存一致性问题。现在CPU都是多核的，由于L1/L2 Cache是多个核心各自独有的，此时就会出现缓存一致性问题。假设A核心和B核心同时运行两个线程，操作同一个变量i，初始值为0，此时在A和B的L1/L2 Cache中都会存在i的缓存数据，假设A中的线程执行了i++，由于写回策略，不会将数据写回内存，此时A中i的数据和B中i的数据就不一致了

为了解决这个问题，需要满足两点

- 写传播，当某个CPU核心发生写操作时，需要把该事件广播给其他核心 
- 事物的串行化：假设有多个核心对同一个数据进行修改，同步给其他核心时，要保证数据修改的顺序是一样的 写传播是通过总线嗅探实现的，当A核心修改了L1 Cache中i变量的值，通过总线将这个事件广播给其他所有的核心，每个CPU核心都会监听总线上的广播事件，并检查是否有相同数据在自己的L1 Cache中，如果存在，则进行修改

MESI协议基于总线嗅探机制实现了事物串形化。

MESI协议中有四个状态，这四个状态用来表示Cache Line的不同状态 

- Modified，已修改。脏标记，表示该Cache Block上的数据已经被更新过，但是还没写入内存 
- Exclusion，独占。数据只存储在一个CPU核心的Cache中，其他CPU核心的Cache中没有该数据，往独占的Cache中写数据，可以直接写入，不需要通知其他CPU核心 
- Shared，共享。数据在多个CPU核心的Cache中都有，更新Cache中数据时，不能直接修改，需要先向其他CPU核心广播一个请求，先把其他核心Cache中对应的Cache Line标记为无效状态，然后在更新当前Cache中的数据 
- Invalidated，已失效。表示该Cache Block里的数据已经失效，不可以读取该状态的数据 

13、CPU从内存读取数据到Cache的时候，并不是一个字节一个字节的读取，而是一块一块的读取，这一块数据被称为CPU Cache Line，Linux下是64字节，意味着L1 Cache一次载入的数据大小为64字节。

现在假设有一个双核心的CPU，这两个 CPU 核心并行运行着两个不同的线程，它们同时从内存中读取两个不同的数据，分别是类型为 long 的变量A和B，这个两个数据的地址在物理内存上是连续的，如果Cahce Line 的大小是64字节，并且变量A在Cahce Line 的开头位置，那么这两个数据是位于同一个Cache Line 中，又因为CPU Cache Line 是CPU 从内存读取数据到 Cache 的单位，所以这两个数据会被同时读入到了两个 CPU核心中各自 Cache 中。

假设A核心读取变量A，A和B属于同一个Cache Line，因此A和B都会被读取到A核心的CPU Cache上，B核心读取变量B，也会将A和B读取到B核心的CPU Cache上，由于B也读取了，因此Cache Line状态为共享。此时A核心修改变量A，将A的Cache Line变为已修改状态，将B的Cache Line变为已失效状态。然后B核心修改变量B，发现Cache Line为已失效状态，同时A核心的Cache Line为已修改状态，因此会将A的Cache Line写入内存，然后B核心重新读取数据到CPU Cache中，执行修改，然后B的Cache Line为已修改状态，A的为已失效状态。如果A和B交替执行这样的步骤，虽然操作的是不同的数据，但是Cache并没有起作用，此时就是CPU Cache伪共享问题

针对CPU缓存伪共享问题，一般通过内存填充解决，即在一个数据之后填充一段内存，使该数据单独在一个CPU Cache Line上，以空间换时间。









